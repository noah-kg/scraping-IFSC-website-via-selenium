{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b00a0f91-3e6b-4b83-bf3c-0db841ea7924",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-07T02:11:38.995939Z",
     "iopub.status.busy": "2023-04-07T02:11:38.995939Z",
     "iopub.status.idle": "2023-04-07T02:11:39.104784Z",
     "shell.execute_reply": "2023-04-07T02:11:39.104784Z",
     "shell.execute_reply.started": "2023-04-07T02:11:38.995939Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pprint\n",
    "import time\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3b766d9d-36c2-41b9-acb0-7a413519ba06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-07T02:23:14.669992Z",
     "iopub.status.busy": "2023-04-07T02:23:14.669992Z",
     "iopub.status.idle": "2023-04-07T02:23:14.809062Z",
     "shell.execute_reply": "2023-04-07T02:23:14.809062Z",
     "shell.execute_reply.started": "2023-04-07T02:23:14.669992Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class IFSCScraper():\n",
    "    \"\"\"\n",
    "    Define a class for the scraper that will be used to gather data from the IFSC website\n",
    "    (ifsc-climbing.org)\n",
    "    Includes methods that allow for scraping different pages and different information\n",
    "    \"\"\"\n",
    "    # Page url\n",
    "    url = 'https://www.ifsc-climbing.org/index.php/world-competition/last-result'\n",
    "    \n",
    "    def __init__(self, debug=False):\n",
    "        \"\"\"\n",
    "        Initialize a scraper object with its own browser instance\n",
    "        Input:\n",
    "            debug - Indicates whether this is a debug instance for quicker development\n",
    "        \"\"\"\n",
    "        self.debug = debug\n",
    "        self.year_events = {}\n",
    "\n",
    "        self.generate_driver()\n",
    "        time.sleep(1)\n",
    "    \n",
    "    def generate_driver(self):\n",
    "        \"\"\"\n",
    "        Initialize Selenium web browser\n",
    "        Input:\n",
    "            N/A\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.driver = webdriver.Firefox()\n",
    "        except:\n",
    "            print('Error: Could not create WebDriver object...')\n",
    "        \n",
    "    def load_page(self, link, timeout=10, wait_after=5):\n",
    "        \"\"\"\n",
    "        Helper function that loads a page and waits for timeout\n",
    "        input:\n",
    "            link - Link to the page we wish to load\n",
    "            timeout - Seconds to wait before timing out\n",
    "            wait_after - Seconds to wait after loading\n",
    "        output:\n",
    "            N/A\n",
    "        \"\"\"\n",
    "\n",
    "        # Visit link\n",
    "        self.driver.get(link)\n",
    "\n",
    "        # Attempt to open link\n",
    "        try:\n",
    "            WebDriverWait(self.driver, timeout).until(EC.visibility_of_element_located((By.XPATH,\n",
    "            \"//div[@class='uk-container']\")))\n",
    "        except TimeoutException:\n",
    "            print(\"Timed out waiting for page \" + link + \" to load\")\n",
    "            self.driver.quit()\n",
    "\n",
    "        # Wait for page to load\n",
    "        time.sleep(wait_after)\n",
    "        \n",
    "    def get_comp_years_and_league(self):\n",
    "        \"\"\"\n",
    "        Parse the world-competition/last-result page to find and return years and leagues\n",
    "        input:\n",
    "            N/A\n",
    "        output:\n",
    "            List of touples containing comp year and league\n",
    "        \"\"\"\n",
    "        year_league_comb = []\n",
    "        \n",
    "        try:\n",
    "            self.load_page(IFSCScraper.url)\n",
    "        except:\n",
    "            print('Error loading page!')\n",
    "            self.driver.quit()\n",
    "            \n",
    "        # The dropdown menus to pick years/leagues/events is in an iframe - we need to switch to it\n",
    "        frame = self.driver.find_element(By.XPATH, '/html/body/div[1]/div[4]/div/iframe')\n",
    "        self.driver.switch_to.frame(frame)\n",
    "\n",
    "        # Dropdown menus for each choice\n",
    "        year_dd     = self.driver.find_element(By.XPATH, '//select[@id=\"years\"]')\n",
    "        league_dd   = self.driver.find_element(By.XPATH, '//select[@id=\"indexes\"]')\n",
    "\n",
    "        # Select all options for 'Year' and 'League' dropdown menus\n",
    "        year_opts = Select(year_dd).options\n",
    "        league_opts = Select(league_dd).options\n",
    "\n",
    "        # Extract text of each of the above options\n",
    "        years   = [opt.text for opt in year_opts]\n",
    "        # leagues = [opt.text for opt in league_opts[1:]] # all leagues\n",
    "        league = league_opts[1].text #world cup only for now\n",
    "\n",
    "        year_league_comb = []\n",
    "        for year in years:\n",
    "            if (year, league) not in year_league_comb:\n",
    "                year_league_comb.append((year, league))\n",
    "\n",
    "        return year_league_comb\n",
    "\n",
    "    def get_years_events(self, years):\n",
    "        \"\"\"\n",
    "        Iterate through each year and get that years events\n",
    "        input:\n",
    "            N/A\n",
    "        output:\n",
    "            List of tuples containing comp year and league\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.load_page(IFSCScraper.url)\n",
    "        except:\n",
    "            print('Error loading page!')\n",
    "        \n",
    "        # The dropdown menus to pick years/leagues/events is in an iframe - we need to switch to it\n",
    "        frame = self.driver.find_element(By.XPATH, '/html/body/div[1]/div[4]/div/iframe')\n",
    "        self.driver.switch_to.frame(frame)\n",
    "\n",
    "        # Dropdown menus for each choice\n",
    "        year_dd, league_dd, event_dd, cat_dd = self.get_dropdowns(self.driver)\n",
    "                \n",
    "        # Creating wait\n",
    "        wait = WebDriverWait(self.driver, 10)\n",
    "        \n",
    "        # Iterate through years provided by get_comp_years_and_league\n",
    "        for year in years:                \n",
    "            years_ob   = Select(year_dd).select_by_value(year[0])   #0 is most recent year (2023)\n",
    "            leagues_ob = Select(league_dd).select_by_index(1) #starts at index 1\n",
    "        \n",
    "            # IF THINGS BREAK, UNCOMMENT THIS SECTION\n",
    "            # Selects third dropdown menu, events\n",
    "            # event_dd = self.driver.find_element(By.XPATH, '//select[@id=\"events\"]')\n",
    "            \n",
    "            # Waits for third dropdown to populate with options based on leagues_ob                                        \n",
    "            events_select = Select(event_dd)\n",
    "            wait.until(lambda d: len(events_select.options) > 1)\n",
    "            \n",
    "            # Gets event options and ids for year and add to dictionary\n",
    "            event_opts = Select(event_dd).options\n",
    "            events = [opt.text for opt in event_opts[1:]]\n",
    "            event_ids = [opt.get_attribute(\"value\").split('/')[-1] for opt in event_opts[1:]]\n",
    "            self.year_events[year[0]] = [(event, id) for event, id in zip(events, event_ids)]\n",
    "            \n",
    "            print(f'{year[0]}: {self.check_for_event_results(self.driver, event_dd, events)}')\n",
    "    \n",
    "    def check_for_event_results(self, driver, dd, events):\n",
    "        \"\"\"\n",
    "        Iterate through each event and check if results exist\n",
    "        input:\n",
    "            N/A\n",
    "        output:\n",
    "            unsure yet\n",
    "        \"\"\"\n",
    "        event_has_results = []\n",
    "        for event in events:\n",
    "            # Select event in events dropdown\n",
    "            events_ob = Select(dd).select_by_visible_text(event)\n",
    "\n",
    "            # Select fourth dropdown menu, categories\n",
    "            cat_dd = driver.find_element(By.XPATH, '//select[@id=\"categories\"]')\n",
    "            cat_select = Select(cat_dd)\n",
    "            wait = WebDriverWait(driver, 2)\n",
    "            try:\n",
    "                wait.until(lambda d: len(cat_select.options) > 1)\n",
    "                event_has_results.append(1)\n",
    "            except:\n",
    "                event_has_results.append(0)\n",
    "        return f'{sum(event_has_results)} of {len(events)} events have results!'\n",
    "    \n",
    "    def get_single_year(self, year = '2022'):\n",
    "        \"\"\"\n",
    "        Iterate through each event and check if results exist\n",
    "        input:\n",
    "            driver - selenium instance\n",
    "            year (string) - year to be scraped\n",
    "        output:\n",
    "            df of that year's results\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.load_page(IFSCScraper.url)            \n",
    "            wait = WebDriverWait(self.driver, 10)\n",
    "        except:\n",
    "            print('Error loading page!')\n",
    "        \n",
    "        wait.until(EC.frame_to_be_available_and_switch_to_it((By.CSS_SELECTOR, \"iframe.jch-lazyloaded\")))\n",
    "        \n",
    "        # Dropdown menus for each choice\n",
    "        year_dd, league_dd, event_dd, cat_dd = self.get_dropdowns(self.driver)\n",
    "        \n",
    "        # Select given year and league\n",
    "        year_ob   = Select(year_dd).select_by_visible_text(year)\n",
    "        league_ob = Select(league_dd).select_by_index(1)\n",
    "        \n",
    "        #need to loop through events here!\n",
    "        all_events = self.get_events(self.driver, event_dd)\n",
    "        \n",
    "        ######## TODO: implement another loop for *every* event!        \n",
    "        \n",
    "        category_select = Select(cat_dd)\n",
    "        wait.until(lambda d: len(category_select.options) > 1)\n",
    "        \n",
    "        dfs = []\n",
    "        for cat in category_select.options[1:]:\n",
    "            cat_ob = Select(cat_dd).select_by_visible_text(cat.text) # selects category\n",
    "            \n",
    "            # Finds table with desired data \n",
    "            wait.until(EC.visibility_of_element_located((By.XPATH, '//div[@id=\"table_id_wrapper\"]')))\n",
    "            table_wrapper = self.driver.find_element(By.XPATH, '//div[@id=\"table_id_wrapper\"]')\n",
    "            results = table_wrapper.find_element(By.TAG_NAME, 'tbody').find_elements(By.TAG_NAME, 'tr')\n",
    "            \n",
    "            # Get event name and date\n",
    "            event_details = self.driver.find_element(By.XPATH, '//div[@class=\"labels\"]')\n",
    "            event_results = event_details.find_elements(By.TAG_NAME, 'p')\n",
    "                        \n",
    "            # Gets data and stores it in dictionary\n",
    "            data = []\n",
    "            for result in results:                \n",
    "                details = result.find_elements(By.TAG_NAME, 'td')\n",
    "                temp_dict = {\n",
    "                    \"Rank\": details[0].text,\n",
    "                    \"Name\": f\"{details[1].text} {details[2].text}\",\n",
    "                    \"Country\": details[3].text,\n",
    "                    \"Qualification\": details[4].text,\n",
    "                    \"Semi-Final\": details[5].text,\n",
    "                    \"Final\": details[6].text\n",
    "                }\n",
    "                data.append(temp_dict)\n",
    "                \n",
    "            # Create dataframe after collecting all the data\n",
    "            df = pd.DataFrame.from_dict(data)\n",
    "            dfs.append((cat.text, event_results[0].text, event_results[1].text, df))\n",
    "        return dfs            \n",
    "\n",
    "    def convert_to_csv(self, packed_data):\n",
    "        (category, event, date, data) = packed_data\n",
    "            \n",
    "        return category, event, date, data\n",
    "    \n",
    "    def get_dropdowns(self, driver):\n",
    "        year_dd   = driver.find_element(By.XPATH, '//select[@id=\"years\"]')\n",
    "        league_dd = driver.find_element(By.XPATH, '//select[@id=\"indexes\"]')\n",
    "        event_dd  = driver.find_element(By.XPATH, '//select[@id=\"events\"]')\n",
    "        cat_dd    = driver.find_element(By.XPATH, '//select[@id=\"categories\"]')\n",
    "        \n",
    "        return year_dd, league_dd, event_dd, cat_dd\n",
    "    \n",
    "    def get_events(self, driver, events_dd):\n",
    "        event_opts = Select(events_dd)\n",
    "        wait = WebDriverWait(driver, 10)\n",
    "        wait.until(lambda d: len(event_opts.options) > 1)\n",
    "                    \n",
    "        return [x.text for x in event_opts.options[1:]]\n",
    "        \n",
    "    def end_session(self):\n",
    "        self.driver.quit()\n",
    "    \n",
    "    def scrape_site(self):\n",
    "        self.get_years_events(self.get_comp_years_and_league())\n",
    "        self.end_session()\n",
    "        \n",
    "def display_events(dict):\n",
    "        for k in dict:\n",
    "            print(f'{int(k)}:')\n",
    "            for v in dict[k]:\n",
    "                print('    ', v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f8e6fe95-2e7a-4fa5-9093-6f2d6fab89ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-07T02:23:15.387478Z",
     "iopub.status.busy": "2023-04-07T02:23:15.387478Z",
     "iopub.status.idle": "2023-04-07T02:23:38.067783Z",
     "shell.execute_reply": "2023-04-07T02:23:38.067783Z",
     "shell.execute_reply.started": "2023-04-07T02:23:15.387478Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all events: ['IFSC - Climbing World Cup (B) - Meiringen (SUI) 2022', 'IFSC - Climbing World Cup (B,S) - Seoul (KOR) 2022', 'IFSC - Climbing World Cup (B,S) - Salt Lake City (USA) 2022', 'IFSC - Climbing World Cup (B,S) - Salt Lake City (USA) 2022', 'IFSC - Climbing World Cup (B) - Brixen (ITA) 2022', 'IFSC - Climbing World Cup (B,L) - Innsbruck (AUT) 2022', 'IFSC - Climbing World Cup (L,S) - Villars (SUI) 2022', 'IFSC - Climbing World Cup (L,S) - Chamonix (FRA) 2022', 'IFSC - Climbing World Cup (L) - Briançon (FRA) 2022', 'IFSC - Climbing World Cup (L) - Koper (SLO) 2022', 'IFSC - Climbing World Cup (L,S) - Edinburgh (GBR) 2022', 'IFSC - Climbing World Cup (L,S) - Jakarta (INA) 2022', 'IFSC - Climbing World Cup (B&L) - Morioka, Iwate (JPN) 2022']\n"
     ]
    }
   ],
   "source": [
    "scraper = IFSCScraper()\n",
    "temp = scraper.get_single_year()\n",
    "scraper.end_session()\n",
    "# scraper.scrape_site()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1a5798-d9f9-4c82-be94-acb870d5c3b1",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-07T02:12:03.894310Z",
     "iopub.status.idle": "2023-04-07T02:12:03.894310Z",
     "shell.execute_reply": "2023-04-07T02:12:03.894310Z",
     "shell.execute_reply.started": "2023-04-07T02:12:03.894310Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for item in temp:\n",
    "    scraper.convert_to_csv(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2464f3a2-ebc6-46d1-afb5-adf6bf383b63",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-07T02:12:03.895286Z",
     "iopub.status.idle": "2023-04-07T02:12:03.895286Z",
     "shell.execute_reply": "2023-04-07T02:12:03.895286Z",
     "shell.execute_reply.started": "2023-04-07T02:12:03.895286Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# display_events(scraper.year_events)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
