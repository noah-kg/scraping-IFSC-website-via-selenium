{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fa1373f-a803-4146-b30b-12291b14fd46",
   "metadata": {},
   "source": [
    "# Data Gathering\n",
    "## Import Libraries & Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5f437b8d-efdc-4953-902f-6efb6160713f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-14T01:49:06.640431Z",
     "iopub.status.busy": "2023-04-14T01:49:06.640431Z",
     "iopub.status.idle": "2023-04-14T01:49:06.655071Z",
     "shell.execute_reply": "2023-04-14T01:49:06.655071Z",
     "shell.execute_reply.started": "2023-04-14T01:49:06.640431Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import glob\n",
    "import re\n",
    "import os\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d17bc8-1883-4d02-b297-ad9abb029de3",
   "metadata": {},
   "source": [
    "## Create Directory Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "92492156-0021-4d11-b87a-2ad2f2e193cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-14T01:49:09.429624Z",
     "iopub.status.busy": "2023-04-14T01:49:09.429624Z",
     "iopub.status.idle": "2023-04-14T01:49:09.447192Z",
     "shell.execute_reply": "2023-04-14T01:49:09.447192Z",
     "shell.execute_reply.started": "2023-04-14T01:49:09.429624Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_DIR = os.path.join(\n",
    "    os.path.dirname(os.path.realpath(\"__file__\")), \"data\"\n",
    ")\n",
    "\n",
    "BOULDER_MEN_DIR            = os.path.join(DATA_DIR, \"Boulder/Men\")\n",
    "BOULDER_WOMEN_DIR          = os.path.join(DATA_DIR, \"Boulder/Women\")\n",
    "LEAD_MEN_DIR               = os.path.join(DATA_DIR, \"Lead/Men\")\n",
    "LEAD_WOMEN_DIR             = os.path.join(DATA_DIR, \"Lead/Women\")\n",
    "SPEED_MEN_DIR              = os.path.join(DATA_DIR, \"Speed/Men\")\n",
    "SPEED_WOMEN_DIR            = os.path.join(DATA_DIR, \"Speed/Women\")\n",
    "COMBINED_MEN_DIR           = os.path.join(DATA_DIR, \"Combined/Men\")\n",
    "COMBINED_WOMEN_DIR         = os.path.join(DATA_DIR, \"Combined/Women\")\n",
    "BOULDER_AND_LEAD_MEN_DIR   = os.path.join(DATA_DIR, \"Boulder & Lead/Men\")\n",
    "BOULDER_AND_LEAD_WOMEN_DIR = os.path.join(DATA_DIR, \"Boulder & Lead/Women\")\n",
    "\n",
    "dirs = [BOULDER_MEN_DIR, BOULDER_WOMEN_DIR, LEAD_MEN_DIR, LEAD_WOMEN_DIR,\n",
    "       SPEED_MEN_DIR, SPEED_WOMEN_DIR, COMBINED_MEN_DIR, COMBINED_WOMEN_DIR,\n",
    "       BOULDER_AND_LEAD_MEN_DIR, BOULDER_AND_LEAD_WOMEN_DIR]\n",
    "\n",
    "# Create directory if it doesn't exist\n",
    "for dir in dirs:\n",
    "    if not os.path.exists(dir):\n",
    "        os.makedirs(dir)\n",
    "        \n",
    "# File to store names of events that have already been scraped\n",
    "try:\n",
    "    ALREADY_SCRAPED = os.path.join(DATA_DIR, \"scraped_events.txt\")\n",
    "    # Create file\n",
    "    with open(ALREADY_SCRAPED, 'x') as fp:\n",
    "        pass\n",
    "except:\n",
    "    if os.stat(ALREADY_SCRAPED).st_size == 0:\n",
    "        print(\"No data has been scraped yet!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b2d3c4-a7e4-4804-87c2-8ed71e1df696",
   "metadata": {},
   "source": [
    "## IFSCScraper Class Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "3b766d9d-36c2-41b9-acb0-7a413519ba06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-14T04:53:38.938461Z",
     "iopub.status.busy": "2023-04-14T04:53:38.937485Z",
     "iopub.status.idle": "2023-04-14T04:53:39.059526Z",
     "shell.execute_reply": "2023-04-14T04:53:39.058550Z",
     "shell.execute_reply.started": "2023-04-14T04:53:38.938461Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class IFSCScraper():\n",
    "    \"\"\"\n",
    "    Define a class for the scraper that will be used to gather data from the IFSC website\n",
    "    (ifsc-climbing.org)\n",
    "    Includes methods that allow for scraping different pages and different information\n",
    "    \"\"\"\n",
    "    # Page url\n",
    "    url  = 'https://www.ifsc-climbing.org/index.php/world-competition/last-result'\n",
    "    url2 = 'https://ifsc.results.info/#/athlete/'\n",
    "    \n",
    "    def __init__(self, debug=False):\n",
    "        \"\"\"\n",
    "        Initialize a scraper object with its own browser instance\n",
    "        Input:\n",
    "            debug - Indicates whether this is a debug instance for quicker development\n",
    "        \"\"\"\n",
    "        self.debug = debug\n",
    "        self.year_events = {}\n",
    "\n",
    "        self.generate_driver()            \n",
    "        time.sleep(1)\n",
    "    \n",
    "    def generate_driver(self):\n",
    "        \"\"\"\n",
    "        Initialize Selenium web browser\n",
    "        Input:\n",
    "            N/A\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.driver = webdriver.Firefox()\n",
    "        except:\n",
    "            print('Error: Could not create WebDriver object...')\n",
    "        \n",
    "    def load_page(self, link, athlete_page=0, timeout=10, wait_after=1):\n",
    "        \"\"\"\n",
    "        Helper function that loads a page and waits for timeout\n",
    "        input:\n",
    "            link - Link to the page we wish to load\n",
    "            timeout - Seconds to wait before timing out\n",
    "            wait_after - Seconds to wait after loading\n",
    "        output:\n",
    "            N/A\n",
    "        \"\"\"\n",
    "\n",
    "        # Visit link\n",
    "        self.driver.get(link)\n",
    "        wait = WebDriverWait(self.driver, timeout)\n",
    "\n",
    "        # Attempt to open link\n",
    "        try:\n",
    "            if athlete_page:\n",
    "                wait.until(EC.visibility_of_element_located((By.XPATH, \"//div[@class='athlete-info left-side']\")))\n",
    "            else:\n",
    "                wait.until(EC.visibility_of_element_located((By.XPATH, \"//div[@class='uk-container']\")))\n",
    "        except TimeoutException:\n",
    "            print(\"Timed out waiting for page \" + link + \" to load\")\n",
    "            self.driver.quit()\n",
    "\n",
    "        # Wait for page to load\n",
    "        time.sleep(wait_after)\n",
    "        \n",
    "    def get_comp_years_and_league(self):\n",
    "        \"\"\"\n",
    "        Parse the world-competition/last-result page to find and return years and leagues\n",
    "        input:\n",
    "            N/A\n",
    "        output:\n",
    "            List of tuples containing comp year and league\n",
    "        \"\"\"\n",
    "        year_league_comb = []\n",
    "        \n",
    "        try:\n",
    "            self.load_page(IFSCScraper.url)\n",
    "        except:\n",
    "            print('Error loading page!')\n",
    "            \n",
    "        # The dropdown menus to pick years/leagues/events is in an iframe - we need to switch to it\n",
    "        frame = self.driver.find_element(By.XPATH, '/html/body/div[1]/div[4]/div/iframe')\n",
    "        self.driver.switch_to.frame(frame)\n",
    "\n",
    "        # Dropdown menus for each choice\n",
    "        year_dd     = self.driver.find_element(By.XPATH, '//select[@id=\"years\"]')\n",
    "        league_dd   = self.driver.find_element(By.XPATH, '//select[@id=\"indexes\"]')\n",
    "\n",
    "        # Select all options for 'Year' and 'League' dropdown menus\n",
    "        year_opts = Select(year_dd).options\n",
    "        league_opts = Select(league_dd).options\n",
    "\n",
    "        # Extract text of each of the above options\n",
    "        years   = [opt.text for opt in year_opts]\n",
    "        # leagues = [opt.text for opt in league_opts[1:]] # all leagues\n",
    "        league = league_opts[1].text #world cup only for now\n",
    "\n",
    "        year_league_comb = []\n",
    "        for year in years:\n",
    "            if (year, league) not in year_league_comb:\n",
    "                year_league_comb.append((year, league))\n",
    "\n",
    "        return year_league_comb\n",
    "\n",
    "    def get_years_events(self, years):\n",
    "        \"\"\"\n",
    "        Iterate through each year and get that years events\n",
    "        input:\n",
    "            N/A\n",
    "        output:\n",
    "            List of tuples containing comp year and league\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.load_page(IFSCScraper.url)\n",
    "        except:\n",
    "            print('Error loading page!')\n",
    "        \n",
    "        # The dropdown menus to pick years/leagues/events is in an iframe - we need to switch to it\n",
    "        frame = self.driver.find_element(By.XPATH, '/html/body/div[1]/div[4]/div/iframe')\n",
    "        self.driver.switch_to.frame(frame)\n",
    "\n",
    "        # Dropdown menus for each choice\n",
    "        year_dd, league_dd, event_dd, cat_dd = self.get_dropdowns(self.driver)\n",
    "                \n",
    "        # Creating wait\n",
    "        wait = WebDriverWait(self.driver, 10)\n",
    "        \n",
    "        # Iterate through years provided by get_comp_years_and_league\n",
    "        for year in years:                \n",
    "            years_ob   = Select(year_dd).select_by_value(year[0])   #0 is most recent year (2023)\n",
    "            leagues_ob = Select(league_dd).select_by_index(1) #starts at index 1\n",
    "        \n",
    "            # IF THINGS BREAK, UNCOMMENT THIS SECTION\n",
    "            # Selects third dropdown menu, events\n",
    "            # event_dd = self.driver.find_element(By.XPATH, '//select[@id=\"events\"]')\n",
    "            \n",
    "            # Waits for third dropdown to populate with options based on leagues_ob                                        \n",
    "            events_select = Select(event_dd)\n",
    "            wait.until(lambda d: len(events_select.options) > 1)\n",
    "            \n",
    "            # Gets event options and ids for year and add to dictionary\n",
    "            event_opts = Select(event_dd).options\n",
    "            events = [opt.text for opt in event_opts[1:]]\n",
    "            event_ids = [opt.get_attribute(\"value\").split('/')[-1] for opt in event_opts[1:]]\n",
    "            self.year_events[year[0]] = [(event, id) for event, id in zip(events, event_ids)]\n",
    "            \n",
    "            print(f'{year[0]}: {self.check_for_event_results(self.driver, event_dd, events)}')\n",
    "    \n",
    "    def check_for_event_results(self, driver, dd, events):\n",
    "        \"\"\"\n",
    "        Iterate through each event and check if results exist\n",
    "        input:\n",
    "            N/A\n",
    "        output:\n",
    "            unsure yet\n",
    "        \"\"\"\n",
    "        event_has_results = []\n",
    "        for event in events:\n",
    "            # Select event in events dropdown\n",
    "            events_ob = Select(dd).select_by_visible_text(event)\n",
    "\n",
    "            # Select fourth dropdown menu, categories\n",
    "            cat_dd = driver.find_element(By.XPATH, '//select[@id=\"categories\"]')\n",
    "            cat_select = Select(cat_dd)\n",
    "            wait = WebDriverWait(driver, 2)\n",
    "            try:\n",
    "                wait.until(lambda d: len(cat_select.options) > 1)\n",
    "                event_has_results.append(1)\n",
    "            except:\n",
    "                event_has_results.append(0)\n",
    "        return f'{sum(event_has_results)} of {len(events)} events have results!'\n",
    "    \n",
    "    def get_year_list(self):\n",
    "        try:\n",
    "            self.load_page(IFSCScraper.url)            \n",
    "            wait = WebDriverWait(self.driver, 5)\n",
    "            \n",
    "            # The data we are after resides within an iframe\n",
    "            wait.until(EC.frame_to_be_available_and_switch_to_it((By.CSS_SELECTOR, \"iframe.jch-lazyloaded\")))\n",
    "        except:\n",
    "            print('Error loading page!')\n",
    "            \n",
    "        # Dropdown menus for each choice\n",
    "        year_dd, league_dd, event_dd, cat_dd = self.get_dropdowns(self.driver)\n",
    "        year_opts = Select(year_dd).options\n",
    "        return [year.text for year in year_opts]\n",
    "    \n",
    "    def get_single_year(self, year = '2022'):\n",
    "        \"\"\"\n",
    "        Fully scrape each event for a given year\n",
    "        input:\n",
    "            year (string) - year to be scraped\n",
    "        output:\n",
    "            List of tuples (category, title, date, dataframe) to \n",
    "            be passed into function that generates actual .csv file\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.load_page(IFSCScraper.url)            \n",
    "            wait = WebDriverWait(self.driver, 8)\n",
    "            \n",
    "            # The data we are after resides within an iframe\n",
    "            wait.until(EC.frame_to_be_available_and_switch_to_it((By.CSS_SELECTOR, \"iframe.jch-lazyloaded\")))\n",
    "            print(f'Scraping {year}...')\n",
    "        except:\n",
    "            print('Error loading page!')        \n",
    "        \n",
    "        # Dropdown menus for each choice\n",
    "        year_dd, league_dd, event_dd, cat_dd = self.get_dropdowns(self.driver)\n",
    "        \n",
    "        # Select given year and league\n",
    "        year_ob   = Select(year_dd).select_by_visible_text(year)\n",
    "        league_ob = Select(league_dd).select_by_index(1)\n",
    "        \n",
    "        # Get list of all events for the year\n",
    "        all_events = self.get_events(self.driver, event_dd)\n",
    "        \n",
    "        # Loop through each event, scrape results, and generate .csv file\n",
    "        dfs = []\n",
    "        for i, event in enumerate(all_events):\n",
    "            # Implement check to see if event has already been scraped\n",
    "            if self.check_if_scraped(event) and all_events[i] != all_events[i-1]:\n",
    "                print(f'--Already scraped {event}!')\n",
    "                continue\n",
    "            # Some of the events aren't actually events, but more qualification rounds, and \n",
    "            # they don't list the results correctly, which will cause errors. The common thread\n",
    "            # is the naming of them.\n",
    "            elif event.count('(') < 1:\n",
    "                print(f'--Skipping {event}...')\n",
    "                continue\n",
    "            else:\n",
    "                # Set this flag for special cases where two events share the same name (rare)\n",
    "                same_event_name = True if all_events[i] == all_events[i-1] else False\n",
    "                                    \n",
    "                # Select event\n",
    "                if same_event_name:\n",
    "                    event_ob = Select(event_dd).select_by_index(i+1)\n",
    "                else:\n",
    "                    event_ob = Select(event_dd).select_by_visible_text(event)\n",
    "                    \n",
    "                category_select = Select(cat_dd)\n",
    "\n",
    "                # Some events were cancelled or don't have results listed, check for it here\n",
    "                try:\n",
    "                    wait.until(lambda d: len(category_select.options) > 1)\n",
    "                    if not self.check_if_scraped(event):\n",
    "                        # self.add_to_scraped_file(event)\n",
    "                        print(f'--Scraping {event}...')\n",
    "                except:\n",
    "                    print(f'--No data for {event}!')\n",
    "                    continue\n",
    "\n",
    "                # Get results for each category\n",
    "                for cat in category_select.options[1:]:\n",
    "                    cat_ob = Select(cat_dd).select_by_visible_text(cat.text) # selects category\n",
    "\n",
    "                    # Finds table with desired data\n",
    "                    try:\n",
    "                        wait.until(EC.visibility_of_element_located((By.XPATH, '//div[@id=\"table_id_wrapper\"]')))\n",
    "                    except:\n",
    "                        print(f'----No data for {cat.text}!')\n",
    "                        continue\n",
    "\n",
    "                    table_wrapper = self.driver.find_element(By.XPATH, '//div[@id=\"table_id_wrapper\"]')\n",
    "                    results = table_wrapper.find_element(By.TAG_NAME, 'tbody').find_elements(By.TAG_NAME, 'tr')\n",
    "\n",
    "                    # Get event name and date\n",
    "                    event_details = self.driver.find_element(By.XPATH, '//div[@class=\"labels\"]')\n",
    "                    event_results = event_details.find_elements(By.TAG_NAME, 'p') # Event title & date\n",
    "\n",
    "                    # Get filename to check if it exists already\n",
    "                    file = self.generate_filename((cat.text, event_results[0].text, event_results[1].text))\n",
    "                    text = '--' + file\n",
    "                    path = self.get_dir(cat.text)\n",
    "                    \n",
    "                    if same_event_name:\n",
    "                        text = text[:-4] + '2' + '.csv'\n",
    "                        file = file[:-4] + '2' + '.csv'\n",
    "                    \n",
    "                    filepath = os.path.join(path, file)\n",
    "                                        \n",
    "                    # Checks if the filename has been added to the .txt, AND if the file exists\n",
    "                    if self.check_if_scraped(text, filepath):\n",
    "                        continue\n",
    "                    else:\n",
    "                        print(f'----Scraping {cat.text}...')\n",
    "                        \n",
    "                        # Data (list of dictionaries) contains each climber's results\n",
    "                        data = []\n",
    "                        for result in results:\n",
    "                            # Each climber's result stored in dict\n",
    "                            temp_dict = self.scrape_results(event, result, cat.text)\n",
    "                            \n",
    "                            if temp_dict:\n",
    "                                data.append(temp_dict)\n",
    "                            else:\n",
    "                                print(f'----Data format error for {cat.text}!')\n",
    "\n",
    "                        # Create dataframe after collecting all the data\n",
    "                        df = pd.DataFrame.from_dict(data)\n",
    "                        \n",
    "                        # Convert raw results into a .csv and marks file as scraped\n",
    "                        self.convert_to_csv(file, cat.text, df)\n",
    "                        self.add_to_scraped_file('--' + file)\n",
    "                        \n",
    "                # All categories for the event have been scraped\n",
    "                self.add_to_scraped_file(event)\n",
    "                        \n",
    "    def get_athlete_height(self, athlete_id):\n",
    "        \"\"\"\n",
    "        Scrape athlete page for climber's height\n",
    "        input:\n",
    "            athlete_id (int) - unique id assigned to each climber\n",
    "        output:\n",
    "            Height (in cm)\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.load_page(IFSCScraper.url2 + athlete_id, athlete_page=1)            \n",
    "        except:\n",
    "            print('Error loading page!')\n",
    "            self.driver.quit()\n",
    "        \n",
    "        height_div = self.driver.find_element(By.XPATH, '//div[@class=\"athlete-info left-side\"]')\n",
    "        height_ele = height_div.find_elements(By.TAG_NAME, 'div')[1]\n",
    "        return height_ele.text.split(': ')[1]\n",
    "    \n",
    "    def add_to_scraped_file(self, text):\n",
    "        if not self.check_if_scraped(text):\n",
    "            with open(ALREADY_SCRAPED, 'a') as file:\n",
    "                file.write(f'{text}\\n')\n",
    "                return\n",
    "    \n",
    "    def check_if_scraped(self, text, file = ''):\n",
    "        with open(ALREADY_SCRAPED, 'r') as f:\n",
    "            done = [x.strip() for x in f.readlines()]\n",
    "            \n",
    "        if file:\n",
    "            if text in done and os.path.exists(file):\n",
    "                return True\n",
    "            return False\n",
    "        return text in done\n",
    "\n",
    "    def scrape_results(self, event, result, cat):\n",
    "        details = result.find_elements(By.TAG_NAME, 'td')\n",
    "        athlete_id = details[1].find_element(By.TAG_NAME, 'a').get_attribute('href').split('id=')[1]\n",
    "        \n",
    "        if \"LEAD\" in cat or \"BOULDER\" in cat:\n",
    "            try:\n",
    "                temp_dict = {\n",
    "                    \"Event\": event,\n",
    "                    \"ID\": athlete_id,\n",
    "                    \"Rank\": details[0].text,\n",
    "                    \"Name\": f\"{details[1].text} {details[2].text}\",\n",
    "                    \"Country\": details[3].text,\n",
    "                    \"Qualification\": details[4].text,\n",
    "                    \"Semi-Final\": details[5].text,\n",
    "                    \"Final\": details[6].text\n",
    "                }\n",
    "            except:\n",
    "                return False\n",
    "        elif \"SPEED\" in cat:\n",
    "            try:\n",
    "                temp_dict = {\n",
    "                    \"Event\": event,\n",
    "                    \"ID\": athlete_id,\n",
    "                    \"Rank\": details[0].text,\n",
    "                    \"Name\": f\"{details[1].text} {details[2].text}\",\n",
    "                    \"Country\": details[3].text,\n",
    "                    \"Qualification\": details[4].text,\n",
    "                    \"Final\": details[5].text\n",
    "                }\n",
    "            except:\n",
    "                return False\n",
    "        else:\n",
    "            try:\n",
    "                temp_dict = {\n",
    "                    \"Event\": event,\n",
    "                    \"ID\": athlete_id,\n",
    "                    \"Rank\": details[0].text,\n",
    "                    \"Name\": f\"{details[1].text} {details[2].text}\",\n",
    "                    \"Country\": details[3].text,\n",
    "                    \"Qualification\": details[4].text\n",
    "                }\n",
    "            except:\n",
    "                return False\n",
    "        return temp_dict\n",
    "    \n",
    "    def get_dropdowns(self, driver):\n",
    "        year_dd   = driver.find_element(By.XPATH, '//select[@id=\"years\"]')\n",
    "        league_dd = driver.find_element(By.XPATH, '//select[@id=\"indexes\"]')\n",
    "        event_dd  = driver.find_element(By.XPATH, '//select[@id=\"events\"]')\n",
    "        cat_dd    = driver.find_element(By.XPATH, '//select[@id=\"categories\"]')        \n",
    "        return year_dd, league_dd, event_dd, cat_dd\n",
    "    \n",
    "    def get_events(self, driver, events_dd):\n",
    "        event_opts = Select(events_dd)\n",
    "        wait = WebDriverWait(driver, 10)\n",
    "        wait.until(lambda d: len(event_opts.options) > 1)                    \n",
    "        return [x.text for x in event_opts.options[1:]]\n",
    "    \n",
    "    def generate_filename(self, packed_data):\n",
    "        # Unpacks data\n",
    "        (category, event, date) = packed_data\n",
    "\n",
    "        # Create filename in form of {date}_{event}_{category}\n",
    "        date = ' '.join(date.split()[::-1][:2])       \n",
    "\n",
    "        # Cleans up event name for next part\n",
    "        event = event.replace('- ', '').split()\n",
    "        if event[-1] == 'CANCELLED':\n",
    "            event = ' '.join(event[:-2])\n",
    "        else:\n",
    "            event = ' '.join(event[:-1])\n",
    "\n",
    "        # Uses Regex to clean because not every name has the same format\n",
    "        filename = ' '.join([date, event, category])\n",
    "        filename = re.findall(\"^[^\\(]+|[\\(].*\", filename)\n",
    "        filename[1] = filename[1].split(') ', 1)[1]\n",
    "        filename = (''.join(filename)\n",
    "                    .replace('(','[')\n",
    "                    .replace(')',']')\n",
    "                    .replace(' ', '_')\n",
    "                    .replace(',', '')\n",
    "                    .lower()) + '.csv'        \n",
    "        return filename\n",
    "\n",
    "    def convert_to_csv(self, filename, category, data):\n",
    "        # Figure out correct directory\n",
    "        path = self.get_dir(category)\n",
    "        file = path + f'\\\\{filename}'\n",
    "\n",
    "        # Generates .csv with filename\n",
    "        data.to_csv(file, index=False)\n",
    "            \n",
    "    def get_dir(self, category):\n",
    "        base = category.upper().split()\n",
    "        if \"MEN\" in base:\n",
    "            if \"BOULDER\" in base: return BOULDER_MEN_DIR\n",
    "            if \"LEAD\" in base: return LEAD_MEN_DIR\n",
    "            if \"SPEED\" in base: return SPEED_MEN_DIR\n",
    "            if \"COMBINED\" in base: return COMBINED_MEN_DIR\n",
    "            if \"BOULDER&LEAD\" in base: return BOULDER_AND_LEAD_MEN_DIR\n",
    "        if \"WOMEN\" in base:\n",
    "            if \"BOULDER\" in base: return BOULDER_WOMEN_DIR\n",
    "            if \"LEAD\" in base: return LEAD_WOMEN_DIR\n",
    "            if \"SPEED\" in base: return SPEED_WOMEN_DIR\n",
    "            if \"COMBINED\" in base: return COMBINED_WOMEN_DIR\n",
    "            if \"BOULDER&LEAD\" in base: return BOULDER_AND_LEAD_WOMEN_DIR\n",
    "                \n",
    "    def end_session(self):\n",
    "        self.driver.quit()\n",
    "    \n",
    "    def scrape_site(self):\n",
    "        self.get_years_events(self.get_comp_years_and_league())\n",
    "        self.end_session()\n",
    "        \n",
    "    def scrape_all_ifsc_world_cups(self):\n",
    "        years = self.get_year_list()\n",
    "        for year in years[1:17]: # 2022-2007, 2023 events haven't happened yet\n",
    "            scraper.get_single_year(year)\n",
    "        self.end_session()\n",
    "        \n",
    "def display_events(dict):\n",
    "        for k in dict:\n",
    "            print(f'{int(k)}:')\n",
    "            for v in dict[k]:\n",
    "                print('    ', v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "f8e6fe95-2e7a-4fa5-9093-6f2d6fab89ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-14T04:55:00.921925Z",
     "iopub.status.busy": "2023-04-14T04:55:00.921925Z",
     "iopub.status.idle": "2023-04-14T04:55:15.538604Z",
     "shell.execute_reply": "2023-04-14T04:55:15.538604Z",
     "shell.execute_reply.started": "2023-04-14T04:55:00.921925Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping 2022...\n",
      "--Already scraped IFSC - Climbing World Cup (B) - Meiringen (SUI) 2022!\n",
      "--Already scraped IFSC - Climbing World Cup (B,S) - Seoul (KOR) 2022!\n",
      "--Already scraped IFSC - Climbing World Cup (B,S) - Salt Lake City (USA) 2022!\n",
      "--Already scraped IFSC - Climbing World Cup (B) - Brixen (ITA) 2022!\n",
      "--Already scraped IFSC - Climbing World Cup (B,L) - Innsbruck (AUT) 2022!\n",
      "--Already scraped IFSC - Climbing World Cup (L,S) - Villars (SUI) 2022!\n",
      "--Already scraped IFSC - Climbing World Cup (L,S) - Chamonix (FRA) 2022!\n",
      "--Already scraped IFSC - Climbing World Cup (L) - Briançon (FRA) 2022!\n",
      "--Already scraped IFSC - Climbing World Cup (L) - Koper (SLO) 2022!\n",
      "--Already scraped IFSC - Climbing World Cup (L,S) - Edinburgh (GBR) 2022!\n",
      "--Already scraped IFSC - Climbing World Cup (L,S) - Jakarta (INA) 2022!\n",
      "--Already scraped IFSC - Climbing World Cup (B&L) - Morioka, Iwate (JPN) 2022!\n"
     ]
    }
   ],
   "source": [
    "# Takes ~37 minutes to scrape all years and events\n",
    "scraper = IFSCScraper()\n",
    "# scraper.scrape_all_ifsc_world_cups()\n",
    "scraper.get_single_year('2022')\n",
    "# scraper.end_session()\n",
    "\n",
    "# scraper.get_athlete_height('1929')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337a1306-dd86-418c-b363-88002425b225",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d21895b0-3118-40e9-bd7b-c2ae3810d08c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-14T00:39:13.561149Z",
     "iopub.status.busy": "2023-04-14T00:39:13.561149Z",
     "iopub.status.idle": "2023-04-14T00:39:13.567005Z",
     "shell.execute_reply": "2023-04-14T00:39:13.567005Z",
     "shell.execute_reply.started": "2023-04-14T00:39:13.561149Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean_boulder(df):\n",
    "    # Gets tops and zones for qualifications\n",
    "    df[['Q_Top', 'Q_Zone']] = df['Qualification'].str.split('T', expand=True)\n",
    "    df['Q_Zone'] = df['Q_Zone'].str.split('Z', expand=True)[0]\n",
    "    df[['Qualification', 'Q_Top_Att', 'Q_Zone_Att']] = df['Qualification'].str.split(expand=True)\n",
    "\n",
    "    # Gets tops and zones for semi-finals\n",
    "    df[['S_Top', 'S_Zone']] = df['Semi-Final'].str.split('T', expand=True)\n",
    "    df['S_Zone'] = df['S_Zone'].str.split('Z', expand=True)[0]\n",
    "    df[['Semi-Final', 'S_Top_Att', 'S_Zone_Att']] = df['Semi-Final'].str.split(expand=True)\n",
    "\n",
    "    # Gets tops and zones for finals\n",
    "    df[['F_Top', 'F_Zone']] = df['Final'].str.split('T', expand=True)\n",
    "    df['F_Zone'] = df['F_Zone'].str.split('Z', expand=True)[0]\n",
    "    df[['Final', 'F_Top_Att', 'F_Zone_Att']] = df['Final'].str.split(expand=True)\n",
    "\n",
    "    new_cols = ['Q_Top', 'Q_Zone', 'Q_Top_Att', 'Q_Zone_Att',\n",
    "                'S_Top', 'S_Zone', 'S_Top_Att', 'S_Zone_Att',\n",
    "                'F_Top', 'F_Zone', 'F_Top_Att', 'F_Zone_Att']\n",
    "\n",
    "    # Convert all new columns to int\n",
    "    for col in new_cols:\n",
    "        df[col] = df[col].astype('float', errors = 'ignore')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "571e53f5-0c8f-4768-9e79-7110ba2d908e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-14T04:05:39.921854Z",
     "iopub.status.busy": "2023-04-14T04:05:39.921854Z",
     "iopub.status.idle": "2023-04-14T04:05:42.043490Z",
     "shell.execute_reply": "2023-04-14T04:05:42.043490Z",
     "shell.execute_reply.started": "2023-04-14T04:05:39.921854Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Event</th>\n",
       "      <th>ID</th>\n",
       "      <th>Rank</th>\n",
       "      <th>Name</th>\n",
       "      <th>Country</th>\n",
       "      <th>Qualification</th>\n",
       "      <th>Semi-Final</th>\n",
       "      <th>Final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IFSC Climbing Worldcup (B) - Hall (AUT) 2007</td>\n",
       "      <td>1204</td>\n",
       "      <td>1</td>\n",
       "      <td>KILIAN FISCHHUBER</td>\n",
       "      <td>AUT</td>\n",
       "      <td>6T11 6B9</td>\n",
       "      <td>4T11 4B8</td>\n",
       "      <td>4T8 4B5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IFSC Climbing Worldcup (B) - Hall (AUT) 2007</td>\n",
       "      <td>3577</td>\n",
       "      <td>2</td>\n",
       "      <td>JORG VERHOEVEN</td>\n",
       "      <td>NED</td>\n",
       "      <td>5T9 6B10</td>\n",
       "      <td>3T5 4B4</td>\n",
       "      <td>4T9 4B5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IFSC Climbing Worldcup (B) - Hall (AUT) 2007</td>\n",
       "      <td>4783</td>\n",
       "      <td>3</td>\n",
       "      <td>AKITO MATSUSHIMA</td>\n",
       "      <td>JPN</td>\n",
       "      <td>3T4 6B15</td>\n",
       "      <td>3T10 3B3</td>\n",
       "      <td>2T7 2B4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IFSC Climbing Worldcup (B) - Hall (AUT) 2007</td>\n",
       "      <td>1213</td>\n",
       "      <td>4</td>\n",
       "      <td>DAVID LAMA</td>\n",
       "      <td>AUT</td>\n",
       "      <td>4T7 6B9</td>\n",
       "      <td>3T7 4B8</td>\n",
       "      <td>2T8 4B10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IFSC Climbing Worldcup (B) - Hall (AUT) 2007</td>\n",
       "      <td>849</td>\n",
       "      <td>5</td>\n",
       "      <td>GABRIELE MORONI</td>\n",
       "      <td>ITA</td>\n",
       "      <td>4T11 5B11</td>\n",
       "      <td>3T5 4B5</td>\n",
       "      <td>1T3 3B4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7786</th>\n",
       "      <td>IFSC - Climbing World Cup (B,S) - Seoul (KOR) ...</td>\n",
       "      <td>3665</td>\n",
       "      <td>48</td>\n",
       "      <td>LUKE GOH WEN BIN</td>\n",
       "      <td>SGP</td>\n",
       "      <td>0T1Z 0 2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7787</th>\n",
       "      <td>IFSC - Climbing World Cup (B,S) - Seoul (KOR) ...</td>\n",
       "      <td>11859</td>\n",
       "      <td>48</td>\n",
       "      <td>DOHYEON KIM</td>\n",
       "      <td>KOR</td>\n",
       "      <td>0T1Z 0 2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7788</th>\n",
       "      <td>IFSC - Climbing World Cup (B,S) - Seoul (KOR) ...</td>\n",
       "      <td>2120</td>\n",
       "      <td>51</td>\n",
       "      <td>SUNGHOON PARK</td>\n",
       "      <td>KOR</td>\n",
       "      <td>0T1Z 0 5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7789</th>\n",
       "      <td>IFSC - Climbing World Cup (B,S) - Seoul (KOR) ...</td>\n",
       "      <td>13548</td>\n",
       "      <td>52</td>\n",
       "      <td>MUHAMMAD FERZA FERNADA ABDI</td>\n",
       "      <td>INA</td>\n",
       "      <td>0T0Z 0 0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7790</th>\n",
       "      <td>IFSC - Climbing World Cup (B,S) - Seoul (KOR) ...</td>\n",
       "      <td>13553</td>\n",
       "      <td>52</td>\n",
       "      <td>MINSUNG HAN</td>\n",
       "      <td>KOR</td>\n",
       "      <td>0T0Z 0 0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7791 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Event     ID  Rank  \\\n",
       "0          IFSC Climbing Worldcup (B) - Hall (AUT) 2007   1204     1   \n",
       "1          IFSC Climbing Worldcup (B) - Hall (AUT) 2007   3577     2   \n",
       "2          IFSC Climbing Worldcup (B) - Hall (AUT) 2007   4783     3   \n",
       "3          IFSC Climbing Worldcup (B) - Hall (AUT) 2007   1213     4   \n",
       "4          IFSC Climbing Worldcup (B) - Hall (AUT) 2007    849     5   \n",
       "...                                                 ...    ...   ...   \n",
       "7786  IFSC - Climbing World Cup (B,S) - Seoul (KOR) ...   3665    48   \n",
       "7787  IFSC - Climbing World Cup (B,S) - Seoul (KOR) ...  11859    48   \n",
       "7788  IFSC - Climbing World Cup (B,S) - Seoul (KOR) ...   2120    51   \n",
       "7789  IFSC - Climbing World Cup (B,S) - Seoul (KOR) ...  13548    52   \n",
       "7790  IFSC - Climbing World Cup (B,S) - Seoul (KOR) ...  13553    52   \n",
       "\n",
       "                             Name Country Qualification Semi-Final     Final  \n",
       "0               KILIAN FISCHHUBER     AUT      6T11 6B9   4T11 4B8   4T8 4B5  \n",
       "1                  JORG VERHOEVEN     NED      5T9 6B10    3T5 4B4   4T9 4B5  \n",
       "2                AKITO MATSUSHIMA     JPN      3T4 6B15   3T10 3B3   2T7 2B4  \n",
       "3                      DAVID LAMA     AUT       4T7 6B9    3T7 4B8  2T8 4B10  \n",
       "4                 GABRIELE MORONI     ITA     4T11 5B11    3T5 4B5   1T3 3B4  \n",
       "...                           ...     ...           ...        ...       ...  \n",
       "7786             LUKE GOH WEN BIN     SGP      0T1Z 0 2        NaN       NaN  \n",
       "7787                  DOHYEON KIM     KOR      0T1Z 0 2        NaN       NaN  \n",
       "7788                SUNGHOON PARK     KOR      0T1Z 0 5        NaN       NaN  \n",
       "7789  MUHAMMAD FERZA FERNADA ABDI     INA      0T0Z 0 0        NaN       NaN  \n",
       "7790                  MINSUNG HAN     KOR      0T0Z 0 0        NaN       NaN  \n",
       "\n",
       "[7791 rows x 8 columns]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grabs all .csv files in given directory\n",
    "all_files = glob.glob(os.path.join(BOULDER_MEN_DIR, \"*.csv\"))\n",
    "df = pd.concat((pd.read_csv(f) for f in all_files), ignore_index=True)\n",
    "df['Rank'] = df['Rank'].fillna(-1).astype('int')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "23d8f2c6-d993-47d4-9625-2780b97b1f23",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-14T04:05:47.922235Z",
     "iopub.status.busy": "2023-04-14T04:05:47.922235Z",
     "iopub.status.idle": "2023-04-14T04:05:47.953733Z",
     "shell.execute_reply": "2023-04-14T04:05:47.953733Z",
     "shell.execute_reply.started": "2023-04-14T04:05:47.922235Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Event</th>\n",
       "      <th>ID</th>\n",
       "      <th>Rank</th>\n",
       "      <th>Name</th>\n",
       "      <th>Country</th>\n",
       "      <th>Qualification</th>\n",
       "      <th>Semi-Final</th>\n",
       "      <th>Final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IFSC Climbing Worldcup (B) - Hall (AUT) 2007</td>\n",
       "      <td>1204</td>\n",
       "      <td>1</td>\n",
       "      <td>KILIAN FISCHHUBER</td>\n",
       "      <td>AUT</td>\n",
       "      <td>6T6Z 11 9</td>\n",
       "      <td>4T4Z 11 8</td>\n",
       "      <td>4T4Z 8 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IFSC Climbing Worldcup (B) - Hall (AUT) 2007</td>\n",
       "      <td>3577</td>\n",
       "      <td>2</td>\n",
       "      <td>JORG VERHOEVEN</td>\n",
       "      <td>NED</td>\n",
       "      <td>5T6Z 9 10</td>\n",
       "      <td>3T4Z 5 4</td>\n",
       "      <td>4T4Z 9 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IFSC Climbing Worldcup (B) - Hall (AUT) 2007</td>\n",
       "      <td>4783</td>\n",
       "      <td>3</td>\n",
       "      <td>AKITO MATSUSHIMA</td>\n",
       "      <td>JPN</td>\n",
       "      <td>3T6Z 4 15</td>\n",
       "      <td>3T3Z 10 3</td>\n",
       "      <td>2T2Z 7 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IFSC Climbing Worldcup (B) - Hall (AUT) 2007</td>\n",
       "      <td>1213</td>\n",
       "      <td>4</td>\n",
       "      <td>DAVID LAMA</td>\n",
       "      <td>AUT</td>\n",
       "      <td>4T6Z 7 9</td>\n",
       "      <td>3T4Z 7 8</td>\n",
       "      <td>2T4Z 8 10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IFSC Climbing Worldcup (B) - Hall (AUT) 2007</td>\n",
       "      <td>849</td>\n",
       "      <td>5</td>\n",
       "      <td>GABRIELE MORONI</td>\n",
       "      <td>ITA</td>\n",
       "      <td>4T5Z 11 11</td>\n",
       "      <td>3T4Z 5 5</td>\n",
       "      <td>1T3Z 3 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7786</th>\n",
       "      <td>IFSC - Climbing World Cup (B,S) - Seoul (KOR) ...</td>\n",
       "      <td>3665</td>\n",
       "      <td>48</td>\n",
       "      <td>LUKE GOH WEN BIN</td>\n",
       "      <td>SGP</td>\n",
       "      <td>0T1Z 0 2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7787</th>\n",
       "      <td>IFSC - Climbing World Cup (B,S) - Seoul (KOR) ...</td>\n",
       "      <td>11859</td>\n",
       "      <td>48</td>\n",
       "      <td>DOHYEON KIM</td>\n",
       "      <td>KOR</td>\n",
       "      <td>0T1Z 0 2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7788</th>\n",
       "      <td>IFSC - Climbing World Cup (B,S) - Seoul (KOR) ...</td>\n",
       "      <td>2120</td>\n",
       "      <td>51</td>\n",
       "      <td>SUNGHOON PARK</td>\n",
       "      <td>KOR</td>\n",
       "      <td>0T1Z 0 5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7789</th>\n",
       "      <td>IFSC - Climbing World Cup (B,S) - Seoul (KOR) ...</td>\n",
       "      <td>13548</td>\n",
       "      <td>52</td>\n",
       "      <td>MUHAMMAD FERZA FERNADA ABDI</td>\n",
       "      <td>INA</td>\n",
       "      <td>0T0Z 0 0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7790</th>\n",
       "      <td>IFSC - Climbing World Cup (B,S) - Seoul (KOR) ...</td>\n",
       "      <td>13553</td>\n",
       "      <td>52</td>\n",
       "      <td>MINSUNG HAN</td>\n",
       "      <td>KOR</td>\n",
       "      <td>0T0Z 0 0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7791 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Event     ID  Rank  \\\n",
       "0          IFSC Climbing Worldcup (B) - Hall (AUT) 2007   1204     1   \n",
       "1          IFSC Climbing Worldcup (B) - Hall (AUT) 2007   3577     2   \n",
       "2          IFSC Climbing Worldcup (B) - Hall (AUT) 2007   4783     3   \n",
       "3          IFSC Climbing Worldcup (B) - Hall (AUT) 2007   1213     4   \n",
       "4          IFSC Climbing Worldcup (B) - Hall (AUT) 2007    849     5   \n",
       "...                                                 ...    ...   ...   \n",
       "7786  IFSC - Climbing World Cup (B,S) - Seoul (KOR) ...   3665    48   \n",
       "7787  IFSC - Climbing World Cup (B,S) - Seoul (KOR) ...  11859    48   \n",
       "7788  IFSC - Climbing World Cup (B,S) - Seoul (KOR) ...   2120    51   \n",
       "7789  IFSC - Climbing World Cup (B,S) - Seoul (KOR) ...  13548    52   \n",
       "7790  IFSC - Climbing World Cup (B,S) - Seoul (KOR) ...  13553    52   \n",
       "\n",
       "                             Name Country Qualification Semi-Final      Final  \n",
       "0               KILIAN FISCHHUBER     AUT     6T6Z 11 9  4T4Z 11 8   4T4Z 8 5  \n",
       "1                  JORG VERHOEVEN     NED     5T6Z 9 10   3T4Z 5 4   4T4Z 9 5  \n",
       "2                AKITO MATSUSHIMA     JPN     3T6Z 4 15  3T3Z 10 3   2T2Z 7 4  \n",
       "3                      DAVID LAMA     AUT      4T6Z 7 9   3T4Z 7 8  2T4Z 8 10  \n",
       "4                 GABRIELE MORONI     ITA    4T5Z 11 11   3T4Z 5 5   1T3Z 3 4  \n",
       "...                           ...     ...           ...        ...        ...  \n",
       "7786             LUKE GOH WEN BIN     SGP      0T1Z 0 2        NaN        NaN  \n",
       "7787                  DOHYEON KIM     KOR      0T1Z 0 2        NaN        NaN  \n",
       "7788                SUNGHOON PARK     KOR      0T1Z 0 5        NaN        NaN  \n",
       "7789  MUHAMMAD FERZA FERNADA ABDI     INA      0T0Z 0 0        NaN        NaN  \n",
       "7790                  MINSUNG HAN     KOR      0T0Z 0 0        NaN        NaN  \n",
       "\n",
       "[7791 rows x 8 columns]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to correct the old scoring syntax\n",
    "def convert_score(score):\n",
    "    if score:\n",
    "        tmp = str(score)\n",
    "        if 'b' in tmp.lower():\n",
    "            tops, top_att = tmp.lower().split()[0].split('t')\n",
    "            zones, zone_att = tmp.lower().split()[1].split('b')\n",
    "\n",
    "            new_score = tops + 'T' + zones + 'Z ' + top_att + ' ' + zone_att\n",
    "            return new_score\n",
    "        return score\n",
    "    return score\n",
    "\n",
    "# Applies above function to the appropriate columns\n",
    "df['Qualification'] = df['Qualification'].apply(convert_score)\n",
    "df['Semi-Final'] = df['Semi-Final'].apply(convert_score)\n",
    "df['Final'] = df['Final'].apply(convert_score)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "1082ebec-4e3d-491c-96d9-0200d31954b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-14T04:04:13.761752Z",
     "iopub.status.busy": "2023-04-14T04:04:13.761752Z",
     "iopub.status.idle": "2023-04-14T04:04:13.769561Z",
     "shell.execute_reply": "2023-04-14T04:04:13.769561Z",
     "shell.execute_reply.started": "2023-04-14T04:04:13.761752Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# name = 'KOKORO FUJII'\n",
    "# # Gets all rows for Tomoa\n",
    "# df.groupby(df['Name']).get_group(name)\n",
    "\n",
    "# # # Gets number of time Tomoa appeared for each round\n",
    "# # df.groupby(df['Name']).get_group(name).count()['Qualification']\n",
    "# # df.groupby(df['Name']).get_group(name).count()['Semi-Final']\n",
    "# # df.groupby(df['Name']).get_group(name).count()['Final']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3da0ce-7373-46d0-8104-b3e894ac8bfd",
   "metadata": {},
   "source": [
    "## Climber Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "ad86eec0-a1d0-4d94-8cd0-8b84b89748a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-14T04:05:51.933685Z",
     "iopub.status.busy": "2023-04-14T04:05:51.933256Z",
     "iopub.status.idle": "2023-04-14T04:05:51.977632Z",
     "shell.execute_reply": "2023-04-14T04:05:51.977632Z",
     "shell.execute_reply.started": "2023-04-14T04:05:51.933685Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Country</th>\n",
       "      <th>Qualification</th>\n",
       "      <th>Semi-Final</th>\n",
       "      <th>Final</th>\n",
       "      <th>Q_Pct</th>\n",
       "      <th>S_Pct</th>\n",
       "      <th>F_Pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1204</td>\n",
       "      <td>KILIAN FISCHHUBER</td>\n",
       "      <td>AUT</td>\n",
       "      <td>56</td>\n",
       "      <td>51</td>\n",
       "      <td>44</td>\n",
       "      <td>100.0</td>\n",
       "      <td>91.07</td>\n",
       "      <td>78.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53</td>\n",
       "      <td>DMITRII SHARAFUTDINOV</td>\n",
       "      <td>RUS</td>\n",
       "      <td>65</td>\n",
       "      <td>53</td>\n",
       "      <td>40</td>\n",
       "      <td>100.0</td>\n",
       "      <td>81.54</td>\n",
       "      <td>61.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>RUSTAM GELMANOV</td>\n",
       "      <td>RUS</td>\n",
       "      <td>69</td>\n",
       "      <td>56</td>\n",
       "      <td>38</td>\n",
       "      <td>100.0</td>\n",
       "      <td>81.16</td>\n",
       "      <td>55.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2272</td>\n",
       "      <td>KOKORO FUJII</td>\n",
       "      <td>JPN</td>\n",
       "      <td>54</td>\n",
       "      <td>48</td>\n",
       "      <td>27</td>\n",
       "      <td>100.0</td>\n",
       "      <td>88.89</td>\n",
       "      <td>50.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>79</td>\n",
       "      <td>ALEKSEY RUBTSOV</td>\n",
       "      <td>RUS</td>\n",
       "      <td>57</td>\n",
       "      <td>50</td>\n",
       "      <td>26</td>\n",
       "      <td>100.0</td>\n",
       "      <td>87.72</td>\n",
       "      <td>45.61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ID                   Name Country  Qualification  Semi-Final  Final  \\\n",
       "0  1204      KILIAN FISCHHUBER     AUT             56          51     44   \n",
       "1    53  DMITRII SHARAFUTDINOV     RUS             65          53     40   \n",
       "2    60        RUSTAM GELMANOV     RUS             69          56     38   \n",
       "3  2272           KOKORO FUJII     JPN             54          48     27   \n",
       "4    79        ALEKSEY RUBTSOV     RUS             57          50     26   \n",
       "\n",
       "   Q_Pct  S_Pct  F_Pct  \n",
       "0  100.0  91.07  78.57  \n",
       "1  100.0  81.54  61.54  \n",
       "2  100.0  81.16  55.07  \n",
       "3  100.0  88.89  50.00  \n",
       "4  100.0  87.72  45.61  "
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new dataframe with athlete's ID, name, and country\n",
    "comp_appearances = df.drop_duplicates(subset=['Name', 'ID'])[['ID', 'Name', 'Country']]\n",
    "\n",
    "# Counts number of appearances per round per climber\n",
    "qual_all = df.groupby(['ID', 'Name'])['Qualification'].count()\n",
    "semi_app = df.groupby(['ID', 'Name'])['Semi-Final'].count()\n",
    "final_app = df.groupby(['ID', 'Name'])['Final'].count()\n",
    "\n",
    "# Merges the above dataframes\n",
    "rounds = pd.merge(pd.merge(qual_all, semi_app , left_on=['ID', 'Name'], right_index=True), final_app, left_on=['ID', 'Name'], right_index=True)\n",
    "comp_appearances = pd.merge(comp_appearances, rounds, left_on=['ID', 'Name'], right_index=True)\n",
    "\n",
    "# Calculates percentages of appearances in each round\n",
    "comp_appearances['Q_Pct'] = round((comp_appearances['Qualification'] / comp_appearances['Qualification']) * 100, 2)\n",
    "comp_appearances['S_Pct'] = round((comp_appearances['Semi-Final'] / comp_appearances['Qualification']) * 100, 2)\n",
    "comp_appearances['F_Pct'] = round((comp_appearances['Final'] / comp_appearances['Qualification']) * 100, 2)\n",
    "comp_appearances = comp_appearances.sort_values('Final', ascending=False).reset_index(drop=True)\n",
    "comp_appearances.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "c51074b7-efb6-439c-8f24-0eeafa309c77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-14T04:05:55.930393Z",
     "iopub.status.busy": "2023-04-14T04:05:55.930393Z",
     "iopub.status.idle": "2023-04-14T04:39:10.140096Z",
     "shell.execute_reply": "2023-04-14T04:39:10.137169Z",
     "shell.execute_reply.started": "2023-04-14T04:05:55.930393Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert 'ID' to string so we can scrape site for heights (~33 minutes)\n",
    "comp_appearances['ID'] = comp_appearances['ID'].apply(str)\n",
    "comp_appearances['Height'] = comp_appearances['ID'].apply(lambda x: scraper.get_athlete_height(x))\n",
    "\n",
    "# Saves data so we don't have to scrape later\n",
    "file = DATA_DIR + '\\\\climber_stats.csv'\n",
    "comp_appearances.to_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "7c237381-c530-4936-bd1b-5dabf4a79b6d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-14T04:46:20.926474Z",
     "iopub.status.busy": "2023-04-14T04:46:20.926474Z",
     "iopub.status.idle": "2023-04-14T04:46:20.935259Z",
     "shell.execute_reply": "2023-04-14T04:46:20.935259Z",
     "shell.execute_reply.started": "2023-04-14T04:46:20.926474Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1149"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of climbers that have a height listed on the IFSC site\n",
    "(comp_appearances['Height'].str.contains('-')).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf4e6b1-785d-4ccc-b651-6306a396314b",
   "metadata": {},
   "source": [
    "## Country Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "566f0563-516a-401b-a44a-3127500cad45",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-14T04:57:24.125874Z",
     "iopub.status.busy": "2023-04-14T04:57:24.125874Z",
     "iopub.status.idle": "2023-04-14T04:57:24.227213Z",
     "shell.execute_reply": "2023-04-14T04:57:24.227213Z",
     "shell.execute_reply.started": "2023-04-14T04:57:24.125874Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Qualification</th>\n",
       "      <th>Semi-Final</th>\n",
       "      <th>Final</th>\n",
       "      <th>Q_Pct</th>\n",
       "      <th>S_Pct</th>\n",
       "      <th>F_Pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>JPN</td>\n",
       "      <td>651</td>\n",
       "      <td>386</td>\n",
       "      <td>134</td>\n",
       "      <td>8.36</td>\n",
       "      <td>18.15</td>\n",
       "      <td>20.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RUS</td>\n",
       "      <td>425</td>\n",
       "      <td>197</td>\n",
       "      <td>109</td>\n",
       "      <td>5.46</td>\n",
       "      <td>9.26</td>\n",
       "      <td>16.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FRA</td>\n",
       "      <td>628</td>\n",
       "      <td>299</td>\n",
       "      <td>81</td>\n",
       "      <td>8.06</td>\n",
       "      <td>14.06</td>\n",
       "      <td>12.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AUT</td>\n",
       "      <td>390</td>\n",
       "      <td>142</td>\n",
       "      <td>75</td>\n",
       "      <td>5.01</td>\n",
       "      <td>6.68</td>\n",
       "      <td>11.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GER</td>\n",
       "      <td>495</td>\n",
       "      <td>180</td>\n",
       "      <td>38</td>\n",
       "      <td>6.35</td>\n",
       "      <td>8.46</td>\n",
       "      <td>5.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SLO</td>\n",
       "      <td>294</td>\n",
       "      <td>131</td>\n",
       "      <td>34</td>\n",
       "      <td>3.77</td>\n",
       "      <td>6.16</td>\n",
       "      <td>5.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KOR</td>\n",
       "      <td>156</td>\n",
       "      <td>58</td>\n",
       "      <td>29</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.73</td>\n",
       "      <td>4.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CZE</td>\n",
       "      <td>173</td>\n",
       "      <td>49</td>\n",
       "      <td>26</td>\n",
       "      <td>2.22</td>\n",
       "      <td>2.30</td>\n",
       "      <td>3.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CAN</td>\n",
       "      <td>333</td>\n",
       "      <td>65</td>\n",
       "      <td>24</td>\n",
       "      <td>4.27</td>\n",
       "      <td>3.06</td>\n",
       "      <td>3.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ITA</td>\n",
       "      <td>345</td>\n",
       "      <td>100</td>\n",
       "      <td>19</td>\n",
       "      <td>4.43</td>\n",
       "      <td>4.70</td>\n",
       "      <td>2.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>USA</td>\n",
       "      <td>380</td>\n",
       "      <td>85</td>\n",
       "      <td>18</td>\n",
       "      <td>4.88</td>\n",
       "      <td>4.00</td>\n",
       "      <td>2.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>GBR</td>\n",
       "      <td>384</td>\n",
       "      <td>101</td>\n",
       "      <td>17</td>\n",
       "      <td>4.93</td>\n",
       "      <td>4.75</td>\n",
       "      <td>2.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NED</td>\n",
       "      <td>244</td>\n",
       "      <td>74</td>\n",
       "      <td>14</td>\n",
       "      <td>3.13</td>\n",
       "      <td>3.48</td>\n",
       "      <td>2.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>UKR</td>\n",
       "      <td>179</td>\n",
       "      <td>39</td>\n",
       "      <td>11</td>\n",
       "      <td>2.30</td>\n",
       "      <td>1.83</td>\n",
       "      <td>1.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>SUI</td>\n",
       "      <td>315</td>\n",
       "      <td>59</td>\n",
       "      <td>10</td>\n",
       "      <td>4.04</td>\n",
       "      <td>2.77</td>\n",
       "      <td>1.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>AUS</td>\n",
       "      <td>137</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>1.76</td>\n",
       "      <td>1.18</td>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ISR</td>\n",
       "      <td>136</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>POL</td>\n",
       "      <td>126</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>1.62</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>BEL</td>\n",
       "      <td>110</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1.41</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>LAT</td>\n",
       "      <td>74</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Country  Qualification  Semi-Final  Final  Q_Pct  S_Pct  F_Pct\n",
       "0      JPN            651         386    134   8.36  18.15  20.43\n",
       "1      RUS            425         197    109   5.46   9.26  16.62\n",
       "2      FRA            628         299     81   8.06  14.06  12.35\n",
       "3      AUT            390         142     75   5.01   6.68  11.43\n",
       "4      GER            495         180     38   6.35   8.46   5.79\n",
       "5      SLO            294         131     34   3.77   6.16   5.18\n",
       "6      KOR            156          58     29   2.00   2.73   4.42\n",
       "7      CZE            173          49     26   2.22   2.30   3.96\n",
       "8      CAN            333          65     24   4.27   3.06   3.66\n",
       "9      ITA            345         100     19   4.43   4.70   2.90\n",
       "10     USA            380          85     18   4.88   4.00   2.74\n",
       "11     GBR            384         101     17   4.93   4.75   2.59\n",
       "12     NED            244          74     14   3.13   3.48   2.13\n",
       "13     UKR            179          39     11   2.30   1.83   1.68\n",
       "14     SUI            315          59     10   4.04   2.77   1.52\n",
       "15     AUS            137          25      4   1.76   1.18   0.61\n",
       "16     ISR            136          20      3   1.75   0.94   0.46\n",
       "17     POL            126          14      2   1.62   0.66   0.30\n",
       "18     BEL            110           8      2   1.41   0.38   0.30\n",
       "19     LAT             74          17      2   0.95   0.80   0.30"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country_appearances = pd.DataFrame()\n",
    "country_appearances['Country'] = comp_appearances['Country'].unique()\n",
    "\n",
    "# Counts number of appearances per round per country\n",
    "qual_all = df.groupby(['Country'])['Qualification'].count()\n",
    "semi_app = df.groupby(['Country'])['Semi-Final'].count()\n",
    "final_app = df.groupby(['Country'])['Final'].count()\n",
    "\n",
    "# Merges the above with our previous dataframe\n",
    "country_appearances = pd.merge(pd.merge(qual_all, semi_app , left_on='Country', right_index=True),\n",
    "                               final_app, left_on='Country', right_index=True)\n",
    "\n",
    "# Calculates percentages of appearances vs total events\n",
    "country_appearances = country_appearances.sort_values('Final', ascending=False).reset_index()\n",
    "country_appearances['Q_Pct'] = round((country_appearances['Qualification'] / country_appearances['Qualification'].sum()) * 100, 2)\n",
    "country_appearances['S_Pct'] = round((country_appearances['Semi-Final'] / country_appearances['Semi-Final'].sum()) * 100, 2)\n",
    "country_appearances['F_Pct'] = round((country_appearances['Final'] / country_appearances['Final'].sum()) * 100, 2)\n",
    "country_appearances.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "c52cefac-e359-4a80-9da0-660f00f64601",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-14T04:58:14.405924Z",
     "iopub.status.busy": "2023-04-14T04:58:14.405924Z",
     "iopub.status.idle": "2023-04-14T04:58:14.428370Z",
     "shell.execute_reply": "2023-04-14T04:58:14.428370Z",
     "shell.execute_reply.started": "2023-04-14T04:58:14.405924Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['AKITO MATSUSHIMA', 'KAZUMA WATANABE', 'HIROSHI OKANO',\n",
       "       'YUKI SUZUKI', 'KEITA MOGAKI', 'MASATOSHI SUGITA',\n",
       "       'DAISUKE KONISHI', 'TSUKURU HORI', 'NOBUYUKI NAGATA',\n",
       "       'TOSHIAKI TAKEUCHI', 'TATSUYA MURAOKA', 'SACHI AMMA',\n",
       "       'ATSUSHI SHIMIZU', 'REI SUGIMOTO', 'SHINTA OZAWA',\n",
       "       'HIROTARO HOSHINA', 'KEITA SETO', 'FUMIHIRO OYAMA', 'HIDEKAZU ITO',\n",
       "       'IMASHI HASHIMOTO', 'SHINPEI HASEGAWA', 'RIMU MURAKAMI',\n",
       "       'SHIGEO IWAI', 'AKITO TSUMORI', 'RYUICHI MURAI', 'MAKOTO YAMAUCHI',\n",
       "       'YOSUKE SENBONGI', 'TATSUMI NITTA', 'TOMOAKI TAKATA',\n",
       "       'MINORU NAKANO', 'KOKORO FUJII', 'YOSHIYUKI OGATA',\n",
       "       'TOMOA NARASAKI', 'MASAHIRO HIGUCHI', 'KEITA WATABE', 'YUJI INOUE',\n",
       "       'KAI HARADA', 'MEICHI NARASAKI', 'YUTA KOBATA', 'TOMOKI MUSHA',\n",
       "       'NAOKI SHIMATANI', 'YUKI HADA', 'RYOHEI KAMEYAMA',\n",
       "       'HAYATO NAKAMURA', 'JUN SHIBANUMA', 'TAISEI ISHIMATSU',\n",
       "       'KAITO WATANABE', 'YUTA IMAIZUMI', 'HIBIKI YAMAUCHI', 'YUYA KITAE',\n",
       "       'TAITO NAKAGAMI', 'TORU KOFUKUDA', 'KEITA DOHI', 'RYOSUKE HIBINO',\n",
       "       'YUKI NAJIMA', 'KEIICHIRO KORENAGA', 'REI KAWAMATA',\n",
       "       'SOYA SHIMADA', 'SOHTA AMAGASA', 'AO YURIKUSA', 'KENTO YAMAGUCHI',\n",
       "       'SATONE YOSHIDA'], dtype=object)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['Country'] == 'JPN']['Name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "4f9935bf-2229-4e38-bb25-17c9949dd6be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-14T04:58:18.597539Z",
     "iopub.status.busy": "2023-04-14T04:58:18.596563Z",
     "iopub.status.idle": "2023-04-14T04:58:18.603394Z",
     "shell.execute_reply": "2023-04-14T04:58:18.603394Z",
     "shell.execute_reply.started": "2023-04-14T04:58:18.597539Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7791\n",
      "2127\n",
      "656\n",
      "99.97999999999999\n",
      "100.01000000000002\n",
      "99.97000000000001\n"
     ]
    }
   ],
   "source": [
    "cols = ['Qualification', 'Semi-Final', 'Final', 'Q_Pct', 'S_Pct', 'F_Pct']\n",
    "for col in cols:\n",
    "    print(country_appearances[col].sum())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
