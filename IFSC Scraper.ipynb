{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b00a0f91-3e6b-4b83-bf3c-0db841ea7924",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-06T20:04:32.701753Z",
     "iopub.status.busy": "2023-04-06T20:04:32.701753Z",
     "iopub.status.idle": "2023-04-06T20:04:32.822351Z",
     "shell.execute_reply": "2023-04-06T20:04:32.822351Z",
     "shell.execute_reply.started": "2023-04-06T20:04:32.701753Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pprint\n",
    "import time\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b766d9d-36c2-41b9-acb0-7a413519ba06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-06T20:04:32.823327Z",
     "iopub.status.busy": "2023-04-06T20:04:32.823327Z",
     "iopub.status.idle": "2023-04-06T20:04:32.838944Z",
     "shell.execute_reply": "2023-04-06T20:04:32.838944Z",
     "shell.execute_reply.started": "2023-04-06T20:04:32.823327Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class IFSCScraper():\n",
    "    \"\"\"\n",
    "    Define a class for the scraper that will be used to gather data from the IFSC website\n",
    "    (ifsc-climbing.org)\n",
    "    Includes methods that allow for scraping different pages and different information\n",
    "    \"\"\"\n",
    "    # Page url\n",
    "    url = 'https://www.ifsc-climbing.org/index.php/world-competition/last-result'\n",
    "    \n",
    "    def __init__(self, debug=False):\n",
    "        \"\"\"\n",
    "        Initialize a scraper object with its own browser instance\n",
    "        Input:\n",
    "            debug - Indicates whether this is a debug instance for quicker development\n",
    "        \"\"\"\n",
    "        self.debug = debug\n",
    "        self.year_league_comb = []\n",
    "        self.year_events = {}\n",
    "\n",
    "        try:\n",
    "            self.browser = webdriver.Firefox()\n",
    "        except:\n",
    "            print('Error: Could not create WebDriver object...')\n",
    "\n",
    "        time.sleep(1)\n",
    "    \n",
    "    def load_page(self, link, timeout=10, wait_after=5):\n",
    "        \"\"\"\n",
    "        Helper function that loads a page and waits for timeout\n",
    "        input:\n",
    "            link - Link to the page we wish to load\n",
    "            timeout - Seconds to wait before timing out\n",
    "            wait_after - Seconds to wait after loading\n",
    "        output:\n",
    "            N/A\n",
    "        \"\"\"\n",
    "\n",
    "        # Visit link\n",
    "        self.browser.get(link)\n",
    "        self.browser.implicitly_wait(3)\n",
    "\n",
    "        # Attempt to open link\n",
    "        try:\n",
    "            WebDriverWait(self.browser, timeout).until(EC.visibility_of_element_located((By.XPATH,\n",
    "            \"//div[@class='uk-container']\")))\n",
    "        except TimeoutException:\n",
    "            print(\"Timed out waiting for page \" + link + \" to load\")\n",
    "            self.browser.quit()\n",
    "\n",
    "        # Wait for page to load\n",
    "        time.sleep(wait_after)\n",
    "        \n",
    "    def get_comp_years_and_league(self):\n",
    "        \"\"\"\n",
    "        Parse the world-competition/last-result page to find and return years and leagues\n",
    "        input:\n",
    "            N/A\n",
    "        output:\n",
    "            List of touples containing comp year and league\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            self.load_page(IFSCScraper.url)\n",
    "            \n",
    "            # The dropdown menus to pick years/leagues/events is in an iframe - we need to switch to it\n",
    "            frame = self.browser.find_element(By.XPATH, '/html/body/div[1]/div[4]/div/iframe')\n",
    "            self.browser.switch_to.frame(frame)\n",
    "            \n",
    "            # Dropdown menus for each choice\n",
    "            year_dd     = self.browser.find_element(By.XPATH, '//select[@id=\"years\"]')\n",
    "            league_dd   = self.browser.find_element(By.XPATH, '//select[@id=\"indexes\"]')\n",
    "            \n",
    "            # Select all options for 'Year' and 'League' dropdown menus\n",
    "            year_opts = Select(year_dd).options\n",
    "            league_opts = Select(league_dd).options\n",
    "            \n",
    "            # Extract text of each of the above options\n",
    "            years   = [opt.text for opt in year_opts]\n",
    "            # leagues = [opt.text for opt in league_opts[1:]] # all leagues\n",
    "            league = league_opts[1].text #world cup only for now\n",
    "                              \n",
    "            for year in years:\n",
    "                if (year, league) not in self.year_league_comb:\n",
    "                    self.year_league_comb.append((year, league))\n",
    "                                                \n",
    "#             # Selenium Select class gets objects in dropdown and puts them in corresponding list\n",
    "#             years_ob   = Select(year_dd).select_by_index(1)     #0 is most recent year\n",
    "#             leagues_ob = Select(league_dd).select_by_index(1)   #starts at index 1\n",
    "            \n",
    "#             # Waits for third dropdown to populate with options based on leagues_ob\n",
    "#             wait = WebDriverWait(self.browser, 10)            \n",
    "#             wait.until(EC.visibility_of_element_located((By.CSS_SELECTOR, \"#events > option:nth-child(2)\")))\n",
    "        \n",
    "#             # Selects third dropdown menu, events\n",
    "#             event_dd = self.browser.find_element(By.XPATH, '//select[@id=\"events\"]')\n",
    "            \n",
    "#             # Wait again for fourth dropdown menu to populate with options based on event_dd            \n",
    "#             wait.until(EC.visibility_of_element_located((By.CSS_SELECTOR, \"#categories > option:nth-child(2)\")))\n",
    "#             category_dd = self.browser.find_element(By.XPATH, '//select[@id=\"categories\"]')\n",
    "            \n",
    "#             # Pick a category to view full results on same page\n",
    "#             # Select(category_dd).select_by_index(1) #mens\n",
    "            \n",
    "#             # Gets options for all four dropdown menus            \n",
    "#             year_opts   = Select(year_dd).options\n",
    "#             league_opts = Select(league_dd).options\n",
    "#             event_opts  = Select(event_dd).options\n",
    "#             cat_opts    = Select(category_dd).options\n",
    "                        \n",
    "#             # Extracts the text from the objects and adds to list\n",
    "#             years      = [x.text for x in year_opts]\n",
    "#             leagues    = [x.text for x in league_opts[1:]]           \n",
    "#             events     = [x.text for x in event_opts[1:]]\n",
    "#             categories = [x.text for x in cat_opts[1:]]\n",
    "            \n",
    "#             event_ids = [opt.get_attribute(\"value\").split('/')[-1] for opt in event_opts[1:]]\n",
    "        except Exception as ex:\n",
    "            print(ex)\n",
    "\n",
    "    def get_years_events(self):\n",
    "        \"\"\"\n",
    "        Iterate through each year and get that years events\n",
    "        input:\n",
    "            N/A\n",
    "        output:\n",
    "            List of touples containing comp year and league\n",
    "        \"\"\"\n",
    "        self.load_page(IFSCScraper.url)\n",
    "        \n",
    "        # The dropdown menus to pick years/leagues/events is in an iframe - we need to switch to it\n",
    "        frame = self.browser.find_element(By.XPATH, '/html/body/div[1]/div[4]/div/iframe')\n",
    "        self.browser.switch_to.frame(frame)\n",
    "        \n",
    "        # Dropdown menus for each choice\n",
    "        year_dd     = self.browser.find_element(By.XPATH, '//select[@id=\"years\"]')\n",
    "        league_dd   = self.browser.find_element(By.XPATH, '//select[@id=\"indexes\"]')\n",
    "        \n",
    "        # Iterate through years provided by get_comp_years_and_league\n",
    "        for year in self.year_league_comb:                \n",
    "            years_ob   = Select(year_dd).select_by_value(year[0])   #0 is most recent year (2023)\n",
    "            leagues_ob = Select(league_dd).select_by_index(1) #starts at index 1\n",
    "        \n",
    "            # Selects third dropdown menu, events\n",
    "            event_dd = self.browser.find_element(By.XPATH, '//select[@id=\"events\"]')\n",
    "            \n",
    "            # Waits for third dropdown to populate with options based on leagues_ob\n",
    "            wait = WebDriverWait(self.browser, 10)            \n",
    "            wait.until(EC.visibility_of_element_located((By.CSS_SELECTOR, \"#events > option:nth-child(2)\")))\n",
    "            \n",
    "            # Gets event options for year and add to dictionary\n",
    "            event_opts = Select(event_dd).options\n",
    "            self.year_events[year[0]] = [opt.text for opt in event_opts[1:]]\n",
    "\n",
    "        # # Wait again for fourth dropdown menu to populate with options based on event_dd            \n",
    "        # wait.until(EC.visibility_of_element_located((By.CSS_SELECTOR, \"#categories > option:nth-child(2)\")))\n",
    "        # category_dd = self.browser.find_element(By.XPATH, '//select[@id=\"categories\"]')\n",
    "    \n",
    "    def check_for_results(self, year, league):\n",
    "        pass\n",
    "    \n",
    "def display_events(dict):\n",
    "        for k in dict:\n",
    "            print(f'{int(k)}:')\n",
    "            for v in dict[k]:\n",
    "                print('    ', v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8e6fe95-2e7a-4fa5-9093-6f2d6fab89ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-06T20:04:32.841871Z",
     "iopub.status.busy": "2023-04-06T20:04:32.840896Z",
     "iopub.status.idle": "2023-04-06T20:05:22.869849Z",
     "shell.execute_reply": "2023-04-06T20:05:22.869849Z",
     "shell.execute_reply.started": "2023-04-06T20:04:32.841871Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "scraper = IFSCScraper()\n",
    "scraper.get_comp_years_and_league()\n",
    "scraper.get_years_events()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2464f3a2-ebc6-46d1-afb5-adf6bf383b63",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-06T20:05:34.868310Z",
     "iopub.status.busy": "2023-04-06T20:05:34.868310Z",
     "iopub.status.idle": "2023-04-06T20:05:34.872217Z",
     "shell.execute_reply": "2023-04-06T20:05:34.872217Z",
     "shell.execute_reply.started": "2023-04-06T20:05:34.868310Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# display_events(scraper.year_events)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
